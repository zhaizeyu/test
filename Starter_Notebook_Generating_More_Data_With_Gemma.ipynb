{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 67121,
          "databundleVersionId": 7806901,
          "sourceType": "competition"
        },
        {
          "sourceId": 7701220,
          "sourceType": "datasetVersion",
          "datasetId": 9
        },
        {
          "sourceId": 11359,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 8749
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Starter Notebook: Generating More Data With Gemma",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaizeyu/test/blob/master/Starter_Notebook_Generating_More_Data_With_Gemma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starter Notebook: Generating More Data With Gemma\n",
        "Our ultimate goal in this competition is to take an original sample of text and a new version of that text rewritten by Gemma, and to figure out what prompt was used to get the new version. A helpful first step is to be able to generate a bunch of examples of what that looks like, so we can then learn the relationships between the original text, rewrite prompt and rewritten text.\n",
        "\n",
        "To generate examples, we'll need a few things:\n",
        "1. A corpus of original texts\n",
        "2. A set of rewrite prompts\n",
        "3. Our model (Gemma!) to use the original text and rewrite prompt to generate a rewritten text\n",
        "\n",
        "Let's tackle them one by one."
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "y9neLXKen101"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating `original_text`\n",
        "While we don't know too much about the original text used in the competition test set,\n",
        "the meta-kaggle dataset provides a corpus of forum messages on kaggle that we can\n",
        "use as a simple example.\n"
      ],
      "metadata": {
        "id": "9ywF9Ahrn103"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"zeyuzhai\",\"key\":\"42dc12af61163cb7e7c0a849dd7e8f49\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "UD9m0yGxt5XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "fVzLzVz2s8W6",
        "outputId": "1362903b-da6d-457c-8cb1-65ba7e4a1235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"username\": \"zeyuzhai\", \"key\": \"42dc12af61163cb7e7c0a849dd7e8f49\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c llm-prompt-recovery"
      ],
      "metadata": {
        "id": "eq4z1mgibtsq",
        "outputId": "667d6eb4-706e-4bc5-e54b-c66e5fe7d506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading llm-prompt-recovery.zip to /content\n",
            "\r  0% 0.00/1.45k [00:00<?, ?B/s]\n",
            "\r100% 1.45k/1.45k [00:00<00:00, 3.28MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip llm-prompt-recovery.zip"
      ],
      "metadata": {
        "id": "x11Lp6zSv0ju",
        "outputId": "2755de66-5032-4dd9-8e5a-073c369034a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  llm-prompt-recovery.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kaggle/meta-kaggle"
      ],
      "metadata": {
        "id": "E2DSiKhMxh1t",
        "outputId": "fd53283b-0f6e-4ef3-95f6-5bcd691f6424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading meta-kaggle.zip to /content\n",
            "100% 6.99G/6.99G [01:32<00:00, 99.1MB/s]\n",
            "100% 6.99G/6.99G [01:32<00:00, 81.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip meta-kaggle.zip ForumMessages.csv"
      ],
      "metadata": {
        "id": "m0rtk5jA3Xnk",
        "outputId": "fb2afdf0-4c77-4e87-b621-3ebe7472f44e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  meta-kaggle.zip\n",
            "  inflating: ForumMessages.csv       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "forum_messsages_df = pd.read_csv('ForumMessages.csv')\n",
        "forum_messsages_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T23:18:42.191551Z",
          "iopub.execute_input": "2024-02-26T23:18:42.191834Z",
          "iopub.status.idle": "2024-02-26T23:18:55.664977Z",
          "shell.execute_reply.started": "2024-02-26T23:18:42.191812Z",
          "shell.execute_reply": "2024-02-26T23:18:55.663995Z"
        },
        "trusted": true,
        "id": "AvZl8d5Hn103",
        "outputId": "48073999-246a-4603-b087-acbd2dbe7648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Id  ForumTopicId  PostUserId             PostDate  \\\n",
              "0  667016        116038     2708132  11/06/2019 18:06:31   \n",
              "1  667014        113221     2358604  11/06/2019 18:05:48   \n",
              "2  667013        116036     1788308  11/06/2019 18:05:43   \n",
              "3  667012        116035     2532029  11/06/2019 18:05:28   \n",
              "4  667011        116032      413189  11/06/2019 18:02:30   \n",
              "\n",
              "   ReplyToForumMessageId                                            Message  \\\n",
              "0                    NaN  <p>Just realized that the true CEF is wrong fo...   \n",
              "1                    NaN                   <p>Looks really helpful ... </p>   \n",
              "2                    NaN  <p>Might someone downloaded train images 180+ ...   \n",
              "3                    NaN  <p>Nice Article, Arjit!\\nJust a small point th...   \n",
              "4               666992.0  <p>Nope it was actually taking lot of space. S...   \n",
              "\n",
              "   Medal MedalAwardDate  \n",
              "0    NaN            NaN  \n",
              "1    3.0     11/13/2019  \n",
              "2    2.0     11/12/2019  \n",
              "3    NaN            NaN  \n",
              "4    NaN            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b57e9fb5-a93f-41fb-8161-f4467640abf7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ForumTopicId</th>\n",
              "      <th>PostUserId</th>\n",
              "      <th>PostDate</th>\n",
              "      <th>ReplyToForumMessageId</th>\n",
              "      <th>Message</th>\n",
              "      <th>Medal</th>\n",
              "      <th>MedalAwardDate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>667016</td>\n",
              "      <td>116038</td>\n",
              "      <td>2708132</td>\n",
              "      <td>11/06/2019 18:06:31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Just realized that the true CEF is wrong fo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>667014</td>\n",
              "      <td>113221</td>\n",
              "      <td>2358604</td>\n",
              "      <td>11/06/2019 18:05:48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Looks really helpful ... &lt;/p&gt;</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11/13/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>667013</td>\n",
              "      <td>116036</td>\n",
              "      <td>1788308</td>\n",
              "      <td>11/06/2019 18:05:43</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Might someone downloaded train images 180+ ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11/12/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>667012</td>\n",
              "      <td>116035</td>\n",
              "      <td>2532029</td>\n",
              "      <td>11/06/2019 18:05:28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Nice Article, Arjit!\\nJust a small point th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>667011</td>\n",
              "      <td>116032</td>\n",
              "      <td>413189</td>\n",
              "      <td>11/06/2019 18:02:30</td>\n",
              "      <td>666992.0</td>\n",
              "      <td>&lt;p&gt;Nope it was actually taking lot of space. S...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b57e9fb5-a93f-41fb-8161-f4467640abf7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b57e9fb5-a93f-41fb-8161-f4467640abf7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b57e9fb5-a93f-41fb-8161-f4467640abf7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3087bdba-30a9-4658-ba1d-4b927a8b1380\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3087bdba-30a9-4658-ba1d-4b927a8b1380')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3087bdba-30a9-4658-ba1d-4b927a8b1380 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "forum_messsages_df"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's grab the first 5 messages to test our generation pipeline:\n",
        "\n",
        "original_texts = forum_messsages_df['Message'][:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T23:18:55.669119Z",
          "iopub.execute_input": "2024-02-26T23:18:55.669391Z",
          "iopub.status.idle": "2024-02-26T23:18:55.673695Z",
          "shell.execute_reply.started": "2024-02-26T23:18:55.669367Z",
          "shell.execute_reply": "2024-02-26T23:18:55.672719Z"
        },
        "trusted": true,
        "id": "9om-FtbJn104"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating `rewrite_prompt`\n",
        "While there are lots of ways to come up with rewrite prompts, for simplicity here are a few random prompts we can use."
      ],
      "metadata": {
        "id": "pFA-Mspvn104"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rewrite_prompts = [\n",
        "    'Explain this to me like I\\'m five.',\n",
        "    'Convert this into a sea shanty.',\n",
        "    'Make this rhyme.',\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T00:00:53.675986Z",
          "iopub.execute_input": "2024-02-27T00:00:53.676986Z",
          "iopub.status.idle": "2024-02-27T00:00:53.681432Z",
          "shell.execute_reply.started": "2024-02-27T00:00:53.676937Z",
          "shell.execute_reply": "2024-02-27T00:00:53.680545Z"
        },
        "trusted": true,
        "id": "KY-DJtVtn104"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating `rewritten_text` with Gemma\n",
        "Now for the fun part! We can use gemma to rewrite our original text samples\n",
        "using the rewrite prompts we created.\n",
        "The code in this cell is borrowed from [the model card](https://www.kaggle.com/models/google/gemma/frameworks/pyTorch/variations/7b-it-quant).\n",
        "The important things to know:\n",
        "\n",
        "We're using the 7B parameter instruction tuned quantized model, which means:\n",
        "\n",
        "- 7B Parameter: this is the larger of the two Gemma models (the other has 2 billion parameters).\n",
        "    In general we expect the larger model to perform better on complex tasks, but\n",
        "    it's more resource intensive. You can see exactly how Gemma 7B compares to to Gemma 2B [here](https://ai.google.dev/gemma).\n",
        "- Instruction Tuned: instruction tuning is an extra training step that results in a model that\n",
        "    can follow user instructions better. Our rewrite prompt is a kind of instruction, so this is what we want!\n",
        "- Quantized: quantization is a way of shrinking the size of a model by reducing the precision of each\n",
        "    parameter; so while our model still has 7 billion parameters, it's easier to run on limited\n",
        "    hardware.\n",
        "\n",
        "At the end of this cell, we'll have a `model` we can call `generate` on with a specially formatted prompt."
      ],
      "metadata": {
        "id": "m-CWSbnPn104"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U immutabledict sentencepiece\n",
        "!git clone https://github.com/google/gemma_pytorch.git\n",
        "!mkdir /kaggle/working/gemma/\n",
        "!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/kaggle/working/gemma_pytorch/\")\n",
        "from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n",
        "from gemma.model import GemmaForCausalLM\n",
        "from gemma.tokenizer import Tokenizer\n",
        "import contextlib\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Load the model\n",
        "VARIANT = \"7b-it-quant\"\n",
        "MACHINE_TYPE = \"cuda\"\n",
        "weights_dir = '/kaggle/input/gemma/pytorch/7b-it-quant/2'\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _set_default_tensor_type(dtype: torch.dtype):\n",
        "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
        "  torch.set_default_dtype(dtype)\n",
        "  yield\n",
        "  torch.set_default_dtype(torch.float)\n",
        "\n",
        "# Model Config.\n",
        "model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n",
        "model_config.tokenizer = os.path.join(weights_dir, \"tokenizer.model\")\n",
        "model_config.quant = \"quant\" in VARIANT\n",
        "\n",
        "# Model.\n",
        "device = torch.device(MACHINE_TYPE)\n",
        "with _set_default_tensor_type(model_config.get_dtype()):\n",
        "  model = GemmaForCausalLM(model_config)\n",
        "  ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n",
        "  model.load_weights(ckpt_path)\n",
        "  model = model.to(device).eval()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T00:00:56.484113Z",
          "iopub.execute_input": "2024-02-27T00:00:56.485153Z",
          "iopub.status.idle": "2024-02-27T00:01:18.443456Z",
          "shell.execute_reply.started": "2024-02-27T00:00:56.485119Z",
          "shell.execute_reply": "2024-02-27T00:01:18.441835Z"
        },
        "trusted": true,
        "id": "07mUshDTn104"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can loop through our input texts, randomly select a rewrite prompt, and see Gemma in action:\n",
        "\n",
        "import random\n",
        "random.seed(0)\n",
        "# This is the prompt format the model expects\n",
        "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "\n",
        "rewrite_data = []\n",
        "\n",
        "for original_text in original_texts:\n",
        "    rewrite_prompt = random.choice(rewrite_prompts)\n",
        "    prompt = f'{rewrite_prompt}\\n{original_text}'\n",
        "    rewritten_text = model.generate(\n",
        "        USER_CHAT_TEMPLATE.format(prompt=prompt),\n",
        "        device=device,\n",
        "        output_len=100,\n",
        "    )\n",
        "    rewrite_data.append({\n",
        "        'original_text': original_text,\n",
        "        'rewrite_prompt': rewrite_prompt,\n",
        "        'rewritten_text': rewritten_text,\n",
        "    })\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T00:01:18.444352Z",
          "iopub.status.idle": "2024-02-27T00:01:18.444741Z",
          "shell.execute_reply.started": "2024-02-27T00:01:18.444566Z",
          "shell.execute_reply": "2024-02-27T00:01:18.444583Z"
        },
        "trusted": true,
        "id": "DYSPdyO-n104"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's turn our generated data into a dataframe, and spot check the first rewrite to see if it makes sense.\n",
        "rewrite_data_df = pd.DataFrame(rewrite_data)\n",
        "rewrite_data_df[:1].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T00:01:18.445724Z",
          "iopub.status.idle": "2024-02-27T00:01:18.446113Z",
          "shell.execute_reply.started": "2024-02-27T00:01:18.445891Z",
          "shell.execute_reply": "2024-02-27T00:01:18.445905Z"
        },
        "trusted": true,
        "id": "8pwPKnGWn105"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps\n",
        "\n",
        "Huzzah! We have a dataset with original texts, rewrite prompts, and rewritten text. Here are a couple of suggestions of next steps you could take to generate a larger, more diverse dataset:\n",
        "1. Add more original text data sources; besides just using all of the forum messages (instead of just the first 5), Kaggle has tons of datasets that would make reasonable input text. Here are few random datasets you could use:\n",
        "    - The `Plot` column from the [Wikipedia Movie Plots dataset](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots).\n",
        "    - The `text` column from the [Emotions dataset](https://www.kaggle.com/datasets/nelgiriyewithana/emotions).\n",
        "    - The `body_text` and `abstract` columns of the [Wikibooks Dataset](https://www.kaggle.com/datasets/dhruvildave/wikibooks-dataset).\n",
        "    \n",
        "    Note that each of these may need different preprocessing; for example, Gemma has a context length of 8192 tokens, so if the text is long, you'll need to truncate it.\n",
        "2. Use gemma to generate original text.\n",
        "3. Expand the list of rewrite prompts. You can come up with them manually, or explore having Gemma write rewrite prompts.\n",
        "4. Play around with the generation of `rewritten_text`:\n",
        "   - How does changing `output_len` affect the length and quality of rewrites?\n",
        "   - Do rewrites with the 2B parameter model differ substantially from the 7B model?\n",
        "   - Can you use [few shot prompting](https://www.promptingguide.ai/techniques/fewshot) to get higher quality rewrites?"
      ],
      "metadata": {
        "id": "R6tnU3Jsn105"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHjg1NVcn105"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}